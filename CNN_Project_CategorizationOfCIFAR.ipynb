{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlmrvOGCCvqR",
        "outputId": "b667b42a-3cc5-49cb-9732-fe19c01c28ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b2df4b64a75a>:10: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  display.set_matplotlib_formats('svg')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda:0' if torch.cuda.is_avalible() else 'cpu')\n"
      ],
      "metadata": {
        "id": "2y4ZSdk4DBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformations\n",
        "transform = T.Compose([ T.ToTensor(),\n",
        "                        T.Normalize([.5,.5,.5],[.5,.5,.5])\n",
        "                       ])\n",
        "'''\n",
        "\n",
        "z-score normalization\n",
        "subtracting mean of each pixel and dividing by std\n",
        "will place the mean to 0 and make the values closer to the mean each pixel value higher than the mean will be +ve and lower will be -ve\n",
        "--\n",
        " Standard deviation is a measure of the dispersion or spread of a set of values. It quantifies how much the values in a dataset vary around the mean (average) value.\n",
        "---\n",
        "T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "\n",
        "\n",
        "\n",
        " The T.Normalize transformation is applied element-wise, meaning it normalizes each channel of the input tensor independently. The parameters passed to T.Normalize are the means and standard deviations for each channel of the input tensor. In your case, the means for each channel are [0.5, 0.5, 0.5], and the standard deviations for each channel are also [0.5, 0.5, 0.5].\n",
        "\n",
        "The normalization formula applied to each channel of the input tensor is:\n",
        "\n",
        "output[channel]=(input[channel]−mean[channel])/std[channel]\n",
        "\n",
        "​\n",
        "\n",
        "\n",
        "In this case, the mean is\n",
        "0.5\n",
        "0.5 and the standard deviation is also\n",
        "0.5\n",
        "0.5 for each channel. This means that each channel's values are scaled to be in the range\n",
        "\n",
        "[−1,1]\n",
        "'''\n",
        "# import the data and simultaneously apply the transform\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform)\n",
        "devtest  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# train=False will download the dataset for testing\n",
        "# split the devtest into two separate sets\n",
        "randidx = np.random.permutation(10000)   # a random permutation of indices\n",
        "# an array of numbers from 0 to 9999 in a random order\n",
        "devset  = Subset(devtest,randidx[:6000]) # Subset for devset\n",
        "testset = Subset(devtest,randidx[6000:]) # Subset for test\n",
        "\n",
        "# transform to dataloaders\n",
        "batchsize    = 32\n",
        "train_loader = DataLoader(trainset,batch_size=batchsize,shuffle=True,drop_last=True)\n",
        "dev_loader   = DataLoader(devset,  batch_size=batchsize) # note: devtest in batches!\n",
        "test_loader  = DataLoader(testset, batch_size=len(testset))"
      ],
      "metadata": {
        "id": "khywV-kLDgnc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}